{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vellamike/pycuda/blob/master/pycuda_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2JZt1GL5D6W"
   },
   "source": [
    "# Introduction to CUDA and PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA_YN7HlGRP5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycuda in ./anaconda3/lib/python3.8/site-packages (2020.1)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in ./anaconda3/lib/python3.8/site-packages (from pycuda) (1.4.4)\n",
      "Requirement already satisfied: decorator>=3.2.0 in ./anaconda3/lib/python3.8/site-packages (from pycuda) (4.4.2)\n",
      "Requirement already satisfied: mako in ./anaconda3/lib/python3.8/site-packages (from pycuda) (1.1.3)\n",
      "Requirement already satisfied: pytools>=2011.2 in ./anaconda3/lib/python3.8/site-packages (from pycuda) (2020.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./anaconda3/lib/python3.8/site-packages (from mako->pycuda) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.6.0 in ./anaconda3/lib/python3.8/site-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
      "Requirement already satisfied: six>=1.8.0 in ./anaconda3/lib/python3.8/site-packages (from pytools>=2011.2->pycuda) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycuda # install cuda\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-g92eSBn5FlC"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(1729)\n",
    "a = numpy.random.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bqm9uTBzJf9X"
   },
   "outputs": [],
   "source": [
    "a = a.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92L9E7WkJhsy"
   },
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1xaAt_NJjSb"
   },
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(a_gpu, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSAkS6e2Jk38"
   },
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "  __global__ void doublify(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2;\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBQ0blkNJnIg"
   },
   "outputs": [],
   "source": [
    "func = mod.get_function(\"doublify\")\n",
    "func(a_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ef82NDPJqWV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3746789  -1.6419895   3.3047218  -1.1505861 ]\n",
      " [ 2.1979356   1.8518921  -1.9868276  -1.7164422 ]\n",
      " [ 0.14977352  1.058711    0.2419031  -0.44884723]\n",
      " [-3.113357    0.11188176  0.32294306 -4.2692833 ]]\n",
      "[[-0.6873394  -0.82099473  1.6523609  -0.57529306]\n",
      " [ 1.0989678   0.92594606 -0.9934138  -0.8582211 ]\n",
      " [ 0.07488676  0.5293555   0.12095155 -0.22442362]\n",
      " [-1.5566785   0.05594088  0.16147153 -2.1346416 ]]\n"
     ]
    }
   ],
   "source": [
    "a_doubled = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
    "print(a_doubled)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXx_p97mJs4Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10967004  0.44301215  0.39626622  0.2497974 ]\n",
      " [ 1.2984973  -1.2804337  -0.97546583 -0.26908663]\n",
      " [-1.1057384  -0.1279927  -0.61782736 -0.98912627]\n",
      " [-2.8598924  -0.7943475  -0.30579695  1.7006376 ]]\n",
      "[[-0.63544416  0.00457387  1.133304    0.14164127]\n",
      " [ 2.091718   -1.2695593  -0.7228234  -0.01938889]\n",
      " [-0.18282357 -1.1190658  -0.6982751   2.1070845 ]\n",
      " [-0.0025556   0.40901005  0.28363675 -1.9498545 ]]\n"
     ]
    }
   ],
   "source": [
    "b = numpy.random.randn(4,4)\n",
    "b = b.astype(numpy.float32)\n",
    "c = numpy.random.randn(4,4)\n",
    "c = c.astype(numpy.float32)\n",
    "\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQYD348qKgva"
   },
   "outputs": [],
   "source": [
    "mod2 = SourceModule(\"\"\"\n",
    "  __global__ void add2(float *a, float *b)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] += b[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vs_5Hb-6Kr-C"
   },
   "outputs": [],
   "source": [
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "cuda.memcpy_htod(c_gpu, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwA4tpOtLE5_"
   },
   "outputs": [],
   "source": [
    "func = mod2.get_function(\"add2\")\n",
    "func(b_gpu,c_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zN8iBYDM_00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5257741   0.447586    1.5295702   0.39143866]\n",
      " [ 3.3902154  -2.549993   -1.6982892  -0.2884755 ]\n",
      " [-1.2885619  -1.2470585  -1.3161025   1.1179583 ]\n",
      " [-2.862448   -0.38533747 -0.0221602  -0.24921691]]\n",
      "[[ 0.10967004  0.44301215  0.39626622  0.2497974 ]\n",
      " [ 1.2984973  -1.2804337  -0.97546583 -0.26908663]\n",
      " [-1.1057384  -0.1279927  -0.61782736 -0.98912627]\n",
      " [-2.8598924  -0.7943475  -0.30579695  1.7006376 ]]\n",
      "[[-0.63544416  0.00457387  1.133304    0.14164127]\n",
      " [ 2.091718   -1.2695593  -0.7228234  -0.01938889]\n",
      " [-0.18282357 -1.1190658  -0.6982751   2.1070845 ]\n",
      " [-0.0025556   0.40901005  0.28363675 -1.9498545 ]]\n"
     ]
    }
   ],
   "source": [
    "added = numpy.empty_like(b)\n",
    "cuda.memcpy_dtoh(added, b_gpu)\n",
    "print(added)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJBVoR8ANgx5"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Write a cuda kernel to find the elementwise square of a matrix\n",
    "2. Write a cuda kernel to find a matrix, which when added to the given matrix results in every element being equal to zero\n",
    "3. Write a cuda kernel to multiply two matrices - how does it scale with matrix size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQYD348qKgva"
   },
   "outputs": [],
   "source": [
    "mod3 = SourceModule(\"\"\"\n",
    "  __global__ void square2(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= a[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(945)\n",
    "d = numpy.random.randn(4,4)\n",
    "d = d.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gpu = cuda.mem_alloc(d.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(d_gpu, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod3.get_function(\"square2\")\n",
    "func(d_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared = numpy.empty_like(d)\n",
    "cuda.memcpy_dtoh(squared, d_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5075933  -3.1299129   0.6720852  -0.26320508]\n",
      " [-1.5865606  -0.9187367  -0.16894463 -0.24052033]\n",
      " [ 0.43718964  0.90926296 -2.130222    0.33575165]\n",
      " [ 0.21738091  0.4459201  -0.17891383  1.7314835 ]]\n",
      "[[2.2728374  9.796354   0.45169854 0.06927691]\n",
      " [2.5171745  0.8440771  0.02854229 0.05785003]\n",
      " [0.19113478 0.8267591  4.537846   0.11272917]\n",
      " [0.04725446 0.19884475 0.03201016 2.998035  ]]\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "print(squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod4 = SourceModule(\"\"\"\n",
    "  __global__ void complement2(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] = - a[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(945)\n",
    "m = numpy.random.randn(4,4)\n",
    "m = m.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gpu = cuda.mem_alloc(m.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(m_gpu, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod4.get_function(\"complement2\")\n",
    "func(m_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement = numpy.empty_like(m)\n",
    "cuda.memcpy_dtoh(complement, m_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5075933  -3.1299129   0.6720852  -0.26320508]\n",
      " [-1.5865606  -0.9187367  -0.16894463 -0.24052033]\n",
      " [ 0.43718964  0.90926296 -2.130222    0.33575165]\n",
      " [ 0.21738091  0.4459201  -0.17891383  1.7314835 ]]\n",
      "[[-1.5075933   3.1299129  -0.6720852   0.26320508]\n",
      " [ 1.5865606   0.9187367   0.16894463  0.24052033]\n",
      " [-0.43718964 -0.90926296  2.130222   -0.33575165]\n",
      " [-0.21738091 -0.4459201   0.17891383 -1.7314835 ]]\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(complement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod5 = SourceModule(\"\"\"\n",
    "  #define N 128\n",
    " \n",
    "  __global__ void multiply(float *a, float *b, float *c)\n",
    "  {\n",
    "    \n",
    "    int row = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int col = threadIdx.y + blockIdx.y * blockDim.y;\n",
    "    \n",
    "    if (row < N && col < N){\n",
    "        c[row * N + col] = 0;\n",
    "        for(int i=0; i<N; ++i) c[row * N + col] += a[row * N + i] * b[N * i + col];\n",
    "    }\n",
    "    \n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "\n",
    "numpy.random.seed(4356)\n",
    "m_a = numpy.random.randn(n,n)\n",
    "m_a = m_a.astype(numpy.float32)\n",
    "m_b = numpy.random.randn(n,n)\n",
    "m_b = m_b.astype(numpy.float32)\n",
    "m_c = numpy.empty([n,n])\n",
    "m_c = m_c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_gpu = cuda.mem_alloc(m_a.nbytes)\n",
    "mb_gpu = cuda.mem_alloc(m_b.nbytes)\n",
    "mc_gpu = cuda.mem_alloc(m_c.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(ma_gpu, m_a)\n",
    "cuda.memcpy_htod(mb_gpu, m_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_x = 16\n",
    "block_y = 16\n",
    "\n",
    "grid_x = (n + block_x - 1) // block_x\n",
    "grid_y = (n + block_y - 1) // block_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:00.000144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from datetime import timedelta\n",
    "\n",
    "func = mod5.get_function(\"multiply\")\n",
    "\n",
    "t0 = perf_counter()\n",
    "func(ma_gpu, mb_gpu, mc_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:00.000313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = perf_counter()\n",
    "func(ma_gpu, mb_gpu, mc_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.Context.synchronize()\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(m_c, mc_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.7378654   4.235635  -17.992908  ...   8.211486   -3.59588\n",
      "   -4.3585978]\n",
      " [  7.2819767   1.769602   -3.9131672 ... -10.885104    9.402001\n",
      "   -2.3365288]\n",
      " [ -4.3908973  -9.043757  -19.409258  ...  13.265595  -13.009256\n",
      "   -3.158233 ]\n",
      " ...\n",
      " [ 14.096389  -12.489891    9.665953  ...  10.440536   -6.866548\n",
      "   22.28903  ]\n",
      " [  9.263469   -4.4498777 -22.920935  ...   1.654692    8.994262\n",
      "   -3.5488815]\n",
      " [ -7.881237    8.017286   -8.048629  ... -15.7865     13.421714\n",
      "    1.4095254]]\n",
      "[[ -3.7378654   4.235635  -17.992908  ...   8.211486   -3.59588\n",
      "   -4.3585978]\n",
      " [  7.2819767   1.769602   -3.9131672 ... -10.885104    9.402001\n",
      "   -2.3365288]\n",
      " [ -4.3908973  -9.043757  -19.409258  ...  13.265595  -13.009256\n",
      "   -3.158233 ]\n",
      " ...\n",
      " [ 14.096389  -12.489891    9.665953  ...  10.440536   -6.866548\n",
      "   22.28903  ]\n",
      " [  9.263469   -4.4498777 -22.920935  ...   1.654692    8.994262\n",
      "   -3.5488815]\n",
      " [ -7.881237    8.017286   -8.048629  ... -15.7865     13.421714\n",
      "    1.4095254]]\n"
     ]
    }
   ],
   "source": [
    "print (numpy.matmul(m_a, m_b))\n",
    "print(m_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod6 = SourceModule(\"\"\"\n",
    "  #define N 4096\n",
    " \n",
    "  __global__ void product(float *a, float *b, float *c)\n",
    "  {\n",
    "    \n",
    "    int row = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int col = threadIdx.y + blockIdx.y * blockDim.y;\n",
    "    \n",
    "    if (row < N && col < N){\n",
    "        c[row * N + col] = 0;\n",
    "        for(int i=0; i<N; ++i) c[row * N + col] += a[row * N + i] * b[N * col + i];\n",
    "    }\n",
    "    \n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4096\n",
    "\n",
    "numpy.random.seed(4356)\n",
    "m_a = numpy.random.randn(n,n)\n",
    "m_a = m_a.astype(numpy.float32)\n",
    "m_b = numpy.random.randn(n,n)\n",
    "m_b = m_b.astype(numpy.float32)\n",
    "m_c = numpy.empty([n,n])\n",
    "m_c = m_c.astype(numpy.float32)\n",
    "m_d = numpy.empty([n,n])\n",
    "m_d = m_c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_gpu = cuda.mem_alloc(m_a.nbytes)\n",
    "mb_gpu = cuda.mem_alloc(m_b.nbytes)\n",
    "mc_gpu = cuda.mem_alloc(m_c.nbytes)\n",
    "md_gpu = cuda.mem_alloc(m_d.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_x = 16\n",
    "block_y = 16\n",
    "\n",
    "grid_x = (n + block_x - 1) // block_x\n",
    "grid_y = (n + block_y - 1) // block_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod6.get_function(\"product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:02.754468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from datetime import timedelta\n",
    "\n",
    "cuda.memcpy_htod(ma_gpu, m_a)\n",
    "cuda.memcpy_htod(mb_gpu, m_b)\n",
    "\n",
    "t0 = perf_counter()\n",
    "\n",
    "func(ma_gpu, mb_gpu, mc_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.memcpy_dtoh(m_c, mc_gpu)\n",
    "func(mb_gpu, ma_gpu, md_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.memcpy_dtoh(m_d, md_gpu)\n",
    "cuda.Context.synchronize()\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:02.714176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = perf_counter()\n",
    "\n",
    "func(ma_gpu, mb_gpu, mc_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.memcpy_dtoh_async(m_c, mc_gpu)\n",
    "func(mb_gpu, ma_gpu, md_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.memcpy_dtoh_async(m_d, md_gpu)\n",
    "cuda.Context.synchronize()\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod7 = SourceModule(\"\"\"\n",
    "  #define N 2048\n",
    " \n",
    "  __global__ void multiply(float *a, float *b, float *c)\n",
    "  {\n",
    "    \n",
    "    for(int row = threadIdx.x + blockIdx.x * blockDim.x; row < N; row += gridDim.x * blockDim.x){\n",
    "        for(int col = threadIdx.y + blockIdx.y * blockDim.y; col < N; col += gridDim.y * blockDim.y){\n",
    "            c[row * N + col] = 0;\n",
    "            for(int i=0; i<N; ++i) c[row * N + col] += a[row * N + i] * b[N * i + col];\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2048\n",
    "\n",
    "numpy.random.seed(4356)\n",
    "m_a = numpy.random.randn(n,n)\n",
    "m_a = m_a.astype(numpy.float32)\n",
    "m_b = numpy.random.randn(n,n)\n",
    "m_b = m_b.astype(numpy.float32)\n",
    "m_c = numpy.empty([n,n])\n",
    "m_c = m_c.astype(numpy.float32)\n",
    "m_d = numpy.empty([n,n])\n",
    "m_d = m_c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_gpu = cuda.mem_alloc(m_a.nbytes)\n",
    "mb_gpu = cuda.mem_alloc(m_b.nbytes)\n",
    "mc_gpu = cuda.mem_alloc(m_c.nbytes)\n",
    "md_gpu = cuda.mem_alloc(m_d.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(ma_gpu, m_a)\n",
    "cuda.memcpy_htod(mb_gpu, m_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_x = 16\n",
    "block_y = 16\n",
    "\n",
    "grid_x = (n + block_x - 1) // block_x\n",
    "grid_y = (n + block_y - 1) // block_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:00.179902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from datetime import timedelta\n",
    "\n",
    "func = mod7.get_function(\"multiply\")\n",
    "\n",
    "t0 = perf_counter()\n",
    "func(ma_gpu, mb_gpu, mc_gpu, block=(block_x, block_y, 1), grid = (grid_x, grid_y, 1))\n",
    "cuda.Context.synchronize()\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> duration: 0:00:00.222918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = perf_counter()\n",
    "func(ma_gpu, mb_gpu, md_gpu, block=(block_x, block_y, 1), grid = (8, 8, 1))\n",
    "cuda.Context.synchronize()\n",
    "duration = perf_counter() - t0\n",
    "\n",
    "print(\"> duration: %s\\n\" % timedelta(seconds=duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(m_c, mc_gpu)\n",
    "cuda.memcpy_dtoh(m_d, md_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(numpy.max(numpy.abs(m_c - m_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pycuda workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
